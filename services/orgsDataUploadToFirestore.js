const fs = require("fs");const path = require("path");const readline = require("readline");const dataLocation = "../public/PetsData";const setting = require("../config/appSetting");const keys = require("../config/credential");const firebase = require('firebase-admin')const googleMapsClient = require("@google/maps").createClient({  key: keys.devKeys.googleMapApi,  Promise: Promise});const orgsDataUploadToFirestore = db => {  let fileIndex = 1;  const rescueGroupAPIKey = keys.devKeys.RescueGroups_ApiKey;  while (fileIndex > 0) {    let fileName = //"test_" + fileIndex + ".json";      rescueGroupAPIKey + "_orgs_" + fileIndex + ".json";    let filePath = path.join(__dirname, dataLocation, fileName);    if (validateFileExist(filePath)) {      dataParse(filePath, fileIndex, db);      fileIndex++;    } else {      fileIndex = -1;    }  }};const addressToGeo = async dataObj => {  let addressStr = `${dataObj.name} ${dataObj.address}  ${dataObj.city} ${    dataObj.zip  }`;  let result = await googleMapsClient    .geocode({ address: addressStr })    .asPromise()    .then(response => {      return response.json.results[0].geometry.location;    })    .catch(err => {      console.log('addrToGeo err-- orgID: ',dataObj.orgID, err);      return null;    });  return result;};const dataParse = async (filePath, fileIndex, db) => {  let bufferArray = [];  let total = 0;  // firestore write limit for single batch => size:10MB, doc amount: 500, rate: 1/s  const docAmountPerBatch = setting.firestore.docAmountPerBatch;  const docRef = db.collection(setting.firestore.orgsCollectionName);  const rl = readline.createInterface({    input: fs.createReadStream(filePath),    terminal: false  });  let linePointer = 1;  rl.on("line", async line => {    let dataObj = JSON.parse(line);    let latlong = await addressToGeo(dataObj);    dataObj.geoLocation = new firebase.firestore.GeoPoint(latlong.lat, latlong.lng);    bufferArray.push(dataObj);    if (linePointer % docAmountPerBatch === 0) {      console.log(        `Pause: file(${fileIndex})'s ReadStream batch limit(${docAmountPerBatch}) reached. -- Line Pointer: ${linePointer} -- temp array size: ${          bufferArray.length        }`      );      rl.pause();    }    linePointer++;  });  rl.on("pause", () => {    let batch = db.batch();    bufferArray.map(org => {      let ref = docRef.doc(org.orgID);      batch.set(ref, org);    });    batch      .commit()      .then(result => {        console.log(          `Resume: file(${fileIndex}) committed ${result.length} documents`        );        total += bufferArray.length;        // after committed batch, reset the temp array for next use.        bufferArray = [];        rl.resume();      })      .catch(err => {        console.log("err", err);      });  });  rl.on("close", () => {    console.log("========================================");    console.log(      `file(index ${fileIndex} on close, total ${total} objects commit succeed`    );    console.log("========================================");  });};const validateFileExist = path => {  try {    return fs.statSync(path).isFile();  } catch (e) {    return false;  }};module.exports = orgsDataUploadToFirestore;